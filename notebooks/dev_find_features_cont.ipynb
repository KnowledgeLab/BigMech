{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datahelpers.constants import iden, ye, ai, ps, up, dn, ar, ni, cexp, qcexp, nw, wi, dist, rdist, pm, \\\n",
    "                                    cpop, cden, ct, affs, aus\n",
    "from os.path import expanduser, join\n",
    "import pandas as pd\n",
    "from bm_support.add_features import generate_feature_groups\n",
    "from bm_support.add_features import normalize_columns\n",
    "from bm_support.supervised_aux import study_sample, metric_selector\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "from numpy.random import RandomState\n",
    "import gzip\n",
    "import pickle\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bm_support.supervised import simple_stratify\n",
    "from bm_support.supervised import select_features_dict, logit_pvalue, report_metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport bm_support.add_features\n",
    "%aimport bm_support.supervised_aux\n",
    "%aimport bm_support.supervised\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_version = 12\n",
    "\n",
    "# origin = 'litgw'\n",
    "# version = 1\n",
    "\n",
    "# origin = 'lit'\n",
    "# version = 8\n",
    "\n",
    "origin = 'gw'\n",
    "version = 11\n",
    "\n",
    "# model_type = 'rf'\n",
    "# seed0 = 17\n",
    "n_trials = 1\n",
    "n_subtrials = 10\n",
    "n_estimators = 17\n",
    "# n_estimators = 55\n",
    "datapath = None\n",
    "# seed0 = 13\n",
    "seed0 = 1\n",
    "n_jobs = 1\n",
    "verbose = True\n",
    "model_type = 'lr'\n",
    "model_type = 'rf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cpop', 'cden', 'ksst', 'nhi', 'affiliations_affind', 'authors_affind', 'future_affind', 'past_affind', 'affiliations_suppind', 'authors_suppind', 'future_suppind', 'past_suppind', 'affiliations_comm_size', 'authors_comm_size', 'future_comm_size', 'past_comm_size', 'affiliations_ncomms', 'authors_ncomms', 'future_ncomms', 'past_ncomms', 'affiliations_ncomponents', 'authors_ncomponents', 'future_ncomponents', 'past_ncomponents', 'affiliations_size_ulist', 'authors_size_ulist', 'future_size_ulist', 'past_size_ulist', 'pre_authors', 'pre_affs']\n",
      "{'cpop': 8, 'cden': 8, 'ksst': 8, 'nhi': 2, 'affiliations_affind': 4, 'authors_affind': 4, 'future_affind': 4, 'past_affind': 4, 'affiliations_suppind': 4, 'authors_suppind': 4, 'future_suppind': 4, 'past_suppind': 4, 'affiliations_comm_size': 4, 'authors_comm_size': 4, 'future_comm_size': 4, 'past_comm_size': 4, 'affiliations_ncomms': 4, 'authors_ncomms': 4, 'future_ncomms': 4, 'past_ncomms': 4, 'affiliations_ncomponents': 4, 'authors_ncomponents': 4, 'future_ncomponents': 4, 'past_ncomponents': 4, 'affiliations_size_ulist': 4, 'authors_size_ulist': 4, 'future_size_ulist': 4, 'past_size_ulist': 4, 'pre_authors': 1, 'pre_affs': 1, 'citations': 12, 'time': 2, 'ai': 1, 'ar': 1, 'cite_count': 1, 'delta_year': 1, 'lincscomm_size': 5, 'lincssame_comm': 5, 'litgweff_comm_size': 12, 'litgwsame_comm': 12, 'litgwcsize_up': 6, 'litgwcsize_dn': 6}\n",
      "188 208\n",
      "['authors', 'cdf_exp', 'dn', 'guess', 'iid', 'len', 'max_year', 'mean', 'min_year', 'new_index', 'pmid', 'pop_density', 'pos', 'qcdf_exp', 'rdist', 'std', 'up', 'wid', 'wos_id', 'year']\n",
      "42\n",
      "Number of col families: 42. Keys: ['affiliations_affind', 'affiliations_comm_size', 'affiliations_ncomms', 'affiliations_ncomponents', 'affiliations_size_ulist', 'affiliations_suppind', 'ai', 'ar', 'authors_affind', 'authors_comm_size', 'authors_ncomms', 'authors_ncomponents', 'authors_size_ulist', 'authors_suppind', 'cden', 'citations', 'cite_count', 'cpop', 'delta_year', 'future_affind', 'future_comm_size', 'future_ncomms', 'future_ncomponents', 'future_size_ulist', 'future_suppind', 'ksst', 'lincscomm_size', 'lincssame_comm', 'litgwcsize_dn', 'litgwcsize_up', 'litgweff_comm_size', 'litgwsame_comm', 'nhi', 'past_affind', 'past_comm_size', 'past_ncomms', 'past_ncomponents', 'past_size_ulist', 'past_suppind', 'pre_affs', 'pre_authors', 'time']\n",
      "Number of col families (excl. future): 36. Keys: ['affiliations_affind', 'affiliations_comm_size', 'affiliations_ncomms', 'affiliations_ncomponents', 'affiliations_size_ulist', 'affiliations_suppind', 'ai', 'ar', 'authors_affind', 'authors_comm_size', 'authors_ncomms', 'authors_ncomponents', 'authors_size_ulist', 'authors_suppind', 'cden', 'citations', 'cite_count', 'cpop', 'delta_year', 'ksst', 'lincscomm_size', 'lincssame_comm', 'litgwcsize_dn', 'litgwcsize_up', 'litgweff_comm_size', 'litgwsame_comm', 'nhi', 'past_affind', 'past_comm_size', 'past_ncomms', 'past_ncomponents', 'past_size_ulist', 'past_suppind', 'pre_affs', 'pre_authors', 'time']\n"
     ]
    }
   ],
   "source": [
    "min_log_alpha = -1\n",
    "max_log_alpha = 1\n",
    "log_reg_dict = {'min_log_alpha': min_log_alpha, 'max_log_alpha': max_log_alpha}\n",
    "\n",
    "eps = 0.2\n",
    "upper_exp, lower_exp = 1 - eps, eps\n",
    "# thrs = [-1e-8, lower_exp, upper_exp, 1.0001e0]\n",
    "if datapath:\n",
    "    col_families = generate_feature_groups(expanduser(join(datapath, 'v12_columns.txt')))\n",
    "else:\n",
    "    col_families = generate_feature_groups(expanduser('~/data/kl/columns/v12_columns.txt'))\n",
    "\n",
    "if verbose:\n",
    "    print('Number of col families: {0}. Keys: {1}'.format(len(col_families), sorted(col_families.keys())))\n",
    "\n",
    "col_families = {k: v for k, v in col_families.items() if 'future' not in k}\n",
    "if verbose:\n",
    "    print('Number of col families (excl. future): {0}. Keys: {1}'.format(len(col_families),\n",
    "                                                                         sorted(col_families.keys())))\n",
    "\n",
    "columns_interest = [x for sublist in col_families.values() for x in sublist]\n",
    "if datapath:\n",
    "    df_path = expanduser(join(datapath, '{0}_{1}_{2}.h5'.format(origin, version, an_version)))\n",
    "else:\n",
    "    df_path = expanduser('~/data/kl/final/{0}_{1}_{2}.h5'.format(origin, version, an_version))\n",
    "df = pd.read_hdf(df_path, key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15494 7878\n",
      "Experimental mask len 887\n",
      "Number of trial features: 90\n",
      "Number of notnull entries (over all features): 14943 from (15494,)\n"
     ]
    }
   ],
   "source": [
    "# mask: literome - mask out a specific interaction\n",
    "mask_lit = (df[up] == 7157) & (df[dn] == 1026)\n",
    "\n",
    "# mask:  interaction with more than 3 claims\n",
    "thr = 3\n",
    "mask_len_ = (df.groupby(ni).apply(lambda x: x.shape[0]) > thr)\n",
    "mask_max_len = df[ni].isin(mask_len_[mask_len_].index)\n",
    "print(mask_max_len.shape[0], sum(mask_max_len))\n",
    "\n",
    "# mask : interactions which are between\n",
    "eps_window_mean = 0.1\n",
    "mean_col = 0.5\n",
    "mask_exp = ((df[cexp] <= lower_exp - eps_window_mean) | (df[cexp] >= upper_exp + eps_window_mean)\n",
    "            # | ((df2[cexp] <= (mean_col + eps_window_mean)) & (df2[cexp] >= (mean_col - eps_window_mean)))\n",
    "            )\n",
    "\n",
    "feature_dict = deepcopy(col_families)\n",
    "# families = ['affiliations_affind', 'affiliations_comm_size', 'affiliations_ncomms',\n",
    "#             'affiliations_ncomponents', 'affiliations_size_ulist', 'affiliations_suppind',\n",
    "#             'ai', 'ar', 'authors_affind', 'authors_comm_size', 'authors_ncomms', 'authors_ncomponents',\n",
    "#             'authors_size_ulist', 'authors_suppind', 'cden', 'citations',\n",
    "#             'cite_count', 'cpop', 'delta_year', 'ksst', 'lincscomm_size', 'lincssame_comm',\n",
    "#             'litgwcsize_dn', 'litgwcsize_up',\n",
    "#             'litgweff_comm_size', 'litgwsame_comm', 'nhi', 'past_affind',\n",
    "#             'past_comm_size', 'past_ncomms', 'past_ncomponents',\n",
    "#             'past_size_ulist', 'past_suppind', 'pre_affs', 'pre_authors', 'time']\n",
    "families = ['affiliations_comm_size',\n",
    "            'ai', 'ar', 'cden', 'citations',\n",
    "            'cite_count', 'cpop', 'delta_year', 'ksst', 'lincscomm_size', 'lincssame_comm',\n",
    "            'litgweff_comm_size', 'litgwsame_comm', 'nhi', 'past_affind',\n",
    "            'past_comm_size', 'time']\n",
    "\n",
    "feature_dict = {k: v for k, v in feature_dict.items() if k in families}\n",
    "\n",
    "trial_features = [x for sublist in feature_dict.values() for x in sublist]\n",
    "\n",
    "feature_dict_inv = {}\n",
    "for k, v in feature_dict.items():\n",
    "    feature_dict_inv.update({x: k for x in v})\n",
    "\n",
    "# mask: not nulls in trial features\n",
    "masks = []\n",
    "for c in trial_features:\n",
    "    masks.append(df[c].notnull())\n",
    "\n",
    "mask_notnull = masks[0]\n",
    "for m in masks[1:]:\n",
    "    mask_notnull &= m\n",
    "\n",
    "print('Experimental mask len {0}'.format(sum(mask_exp)))\n",
    "print('Number of trial features: {0}'.format(len(trial_features)))\n",
    "print('Number of notnull entries (over all features): {0} from {1}'.format(sum(mask_notnull), mask_notnull.shape))\n",
    "\n",
    "if origin != 'gw':\n",
    "    mask_agg = mask_notnull & ~mask_lit\n",
    "else:\n",
    "    mask_agg = mask_notnull\n",
    "\n",
    "dfw = df.loc[mask_agg].copy()\n",
    "\n",
    "#metric to optimize for\n",
    "mm = 'accuracy'\n",
    "# mm = 'precision'\n",
    "\n",
    "nmax = 5000\n",
    "\n",
    "rns = RandomState(seed0)\n",
    "seeds = rns.randint(nmax, size=n_trials)\n",
    "\n",
    "if model_type == 'lr':\n",
    "    dfw = normalize_columns(dfw, trial_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def study_sample_cont(seed, dfw, dist, feature_dict,\n",
    "                 metric_mode, model_type, n_subtrials, n_estimators,\n",
    "                 log_reg_dict={'min_log_alpha': -2., 'max_log_alpha': 2.},\n",
    "                 verbose=False):\n",
    "    nmax = 10000\n",
    "    metric_uniform_exponent = 0.5\n",
    "    mode_scores=None\n",
    "    min_log_alpha, max_log_alpha = log_reg_dict['min_log_alpha'], log_reg_dict['max_log_alpha']\n",
    "    feature_dict_inv = {}\n",
    "    for k, v in feature_dict.items():\n",
    "        feature_dict_inv.update({x: k for x in v})\n",
    "\n",
    "    rns = RandomState(seed)\n",
    "    df_train, df_testgen = train_test_split(dfw, test_size=0.4,\n",
    "                                            random_state=rns, stratify=dfw[dist])\n",
    "\n",
    "    df_valid, df_test = train_test_split(df_testgen, test_size=0.5,\n",
    "                                         random_state=rns)\n",
    "\n",
    "    vc = df_train[dist].value_counts()\n",
    "    if verbose and vc.shape[0] < 5:\n",
    "        print('*** df_train dist vc')\n",
    "        print(vc)\n",
    "    # training on the normalized frequencies\n",
    "    df_train2 = simple_stratify(df_train, dist, seed, ratios=(2, 1, 1))\n",
    "\n",
    "    if model_type == 'rf':\n",
    "        param_dict = {'n_estimators': n_estimators, 'max_features': None, 'n_jobs': 1}\n",
    "    else:\n",
    "        param_dict = {'n_jobs': 1}\n",
    "\n",
    "    meta_agg = []\n",
    "    if model_type == 'rf':\n",
    "        enums = rns.randint(nmax, size=n_subtrials)\n",
    "    elif model_type == 'lr':\n",
    "        delta = (max_log_alpha - min_log_alpha) / n_subtrials\n",
    "        enums = 1e1 ** np.arange(min_log_alpha, max_log_alpha, delta)\n",
    "    else:\n",
    "        enums = []\n",
    "    return df_train2, df_test, df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** df_train dist vc\n",
      "1.0    7944\n",
      "0.0     826\n",
      "2.0     195\n",
      "Name: guess, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, df_valid = study_sample_cont(dfw=dfw, seed=seed0, dist=dist, feature_dict=feature_dict, metric_mode=mm,\n",
    "                                               model_type=model_type,\n",
    "                                               n_subtrials=n_subtrials, n_estimators=n_estimators,\n",
    "                                               log_reg_dict=log_reg_dict, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = 'litgw_comm_im_undir_wei_pNone_eff_comm_size'\n",
    "feature_dict_new = {k: list(v) for k, v in feature_dict.items() if target_column not in v}\n",
    "len(feature_dict), len(feature_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'rf':\n",
    "    param_dict = {'n_estimators': n_estimators, 'max_features': None, 'n_jobs': 1}\n",
    "else:\n",
    "    param_dict = {'n_jobs': 1}\n",
    "\n",
    "meta_agg = []\n",
    "if model_type == 'rf':\n",
    "    enums = rns.randint(nmax, size=n_subtrials)\n",
    "elif model_type == 'lr':\n",
    "    delta = (max_log_alpha - min_log_alpha) / n_subtrials\n",
    "    enums = 1e1 ** np.arange(min_log_alpha, max_log_alpha, delta)\n",
    "else:\n",
    "    enums = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = enums[0]\n",
    "if model_type == 'rf':\n",
    "    param_dict['random_state'] = ii\n",
    "elif model_type == 'lr':\n",
    "    param_dict['C'] = ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 3980}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 3980}\n"
     ]
    }
   ],
   "source": [
    "model_dict = param_dict\n",
    "y_train, y_test = df_train[target_column], df_test[target_column]\n",
    "\n",
    "chosen_features = []\n",
    "chosen_metrics = []\n",
    "chosen_total_metrics = []\n",
    "feature_dict_dyn = deepcopy(feature_dict)\n",
    "feature_dict_inv = {}\n",
    "for k, v in feature_dict.items():\n",
    "    feature_dict_inv.update({x: k for x in v})\n",
    "\n",
    "if verbose:\n",
    "    print('model_dict {0}'.format(model_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_consider = 5\n",
    "trial_features = [x for sublist in feature_dict_dyn.values() for x in sublist]\n",
    "len(trial_features)\n",
    "cur_features = trial_features[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = df_train[cur_features], df_test[cur_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = RandomForestRegressor(**model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=None, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=17, n_jobs=1,\n",
       "           oob_score=False, random_state=3980, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corr': 0.5273485462658444,\n",
       " 'mse': 0.01312455460048995,\n",
       " 'main_metric': 0.01312455460048995}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmetrics = report_metrics(model_, df_valid[cur_features], df_valid[target_column],\n",
    "                          problem_type='regression')\n",
    "rmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corr': 0.4673735955828734,\n",
       " 'mse': 0.013975235251299248,\n",
       " 'main_metric': 0.013975235251299248}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmetrics = report_metrics(model_, df_test[cur_features], df_test[target_column],\n",
    "                          problem_type='regression')\n",
    "rmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corr': 0.7831827946259942,\n",
       " 'mse': 0.021600409081096797,\n",
       " 'main_metric': 0.021600409081096797}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmetrics = report_metrics(model_, df_train[cur_features], df_train[target_column],\n",
    "                          problem_type='regression')\n",
    "rmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cpop', 0.09261631525873423), ('cpoprc', 0.043488408358661045), ('cpop1', 0.022376554564349057), ('cpoprc1', 0.016011590539879238), ('cpop2', 0.028528700022709363), ('cpoprc2', 0.03959154151798805), ('cpop3', 0.013361119822479244), ('cpoprc3', 0.03111474886704313), ('cden', 0.25957864400978375), ('cdenrc', 0.12507584497973356), ('cden1', 0.013255175142452284), ('cdenrc1', 0.016355940292462137), ('cden2', 0.013748914775664516), ('cdenrc2', 0.040361991787341976), ('cden3', 0.016642873913723117), ('cdenrc3', 0.016240996935663138), ('ksst', 0.10027124110025597), ('ksstrc', 0.10986762449722434), ('ksst1', 0.0), ('ksstrc1', 0.0015117736138518453)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(cur_features, model.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = select_features_dict(df_train2, df_test, target,\n",
    "                       feature_dict,\n",
    "                       model_type=model_type,\n",
    "                       max_features_consider=8,\n",
    "                       metric_mode=metric_mode,\n",
    "                       mode_scores=mode_scores,\n",
    "                       metric_uniform_exponent=metric_uniform_exponent,\n",
    "                       model_dict=param_dict,\n",
    "                       verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-419d031227c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "while len(chosen_features) <= max_features_consider and feature_dict_dyn:\n",
    "    trial_features = [x for sublist in feature_dict_dyn.values() for x in sublist]\n",
    "    scalar_metrics = []\n",
    "    cur_metrics = []\n",
    "    for tf in trial_features:\n",
    "        cur_features = chosen_features + [tf]\n",
    "        X_train, X_test = df_train[cur_features], df_test[cur_features]\n",
    "        if model_type == 'rf':\n",
    "            model = RandomForestClassifier(**model_dict)\n",
    "        else:\n",
    "            model = LogisticRegression(**model_dict)\n",
    "        model.fit(X_train, y_train)\n",
    "        rmetrics = report_metrics(model, X_test, y_test, mode_scores, metric_uniform_exponent, metric_mode)\n",
    "        # y_pred = model.predict(X_test)\n",
    "\n",
    "        # corr = np.corrcoef(y_pred, y_test)[0, 1]\n",
    "        # accuracy = accuracy_score(y_test, y_pred)\n",
    "        # precision = precision_score(y_test, y_pred, average=mode_scores)\n",
    "        # recall = recall_score(y_test, y_pred, average=mode_scores)\n",
    "        # f1 = f1_score(y_test, y_pred, average=mode_scores)\n",
    "        # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        # report['confusion'] = conf_matrix\n",
    "        # report['class_report'] = classification_report(y_test, y_pred)\n",
    "        # vector_metrics.append((precision, recall, f1))\n",
    "        # sc_vector_metrics = [np.sum(x**metric_uniform_exponent) for x in [precision, recall, f1]]\n",
    "        scalar_metrics.append(rmetrics['main_metric'])\n",
    "        cur_metrics.append(rmetrics)\n",
    "\n",
    "    add_index = np.nanargmax(np.array(scalar_metrics))\n",
    "\n",
    "    if len(chosen_metrics) > 0:\n",
    "        potential_improvement = 1 - chosen_metrics[-1] / scalar_metrics[add_index]\n",
    "        if potential_improvement < eps_improvement:\n",
    "            if verbose:\n",
    "                print('Terminating early: no improvement.')\n",
    "            break\n",
    "    else:\n",
    "        potential_improvement = 1\n",
    "\n",
    "    current_feature = trial_features[add_index]\n",
    "    feature_group = feature_dict_inv[current_feature]\n",
    "\n",
    "    chosen_metrics.append(scalar_metrics[add_index])\n",
    "\n",
    "    chosen_features.append(current_feature)\n",
    "    chosen_total_metrics.append(cur_metrics[add_index])\n",
    "\n",
    "    if verbose:\n",
    "        print('nf: {0} cfeature: {1} metric: {2:.3f} metric_improv: {3:.2f} %'.format(len(cur_features),\n",
    "              (current_feature[:27]+'...').ljust(30),\n",
    "              chosen_metrics[-1], 100*potential_improvement))\n",
    "\n",
    "    if len(feature_dict[feature_group]) - len(feature_dict_dyn[feature_group]) < 1:\n",
    "        feature_dict_dyn[feature_group].remove(current_feature)\n",
    "    else:\n",
    "        del feature_dict_dyn[feature_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15494 7878\n",
      "Experimental mask len 887\n",
      "Number of trial features: 90\n",
      "Number of notnull entries (over all features): 14943 from (15494,)\n",
      "Starting 1 processes...\n",
      "*** df_train dist vc\n",
      "1.0    7944\n",
      "0.0     826\n",
      "2.0     195\n",
      "Name: guess, dtype: int64\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 4183}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.354 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: delta_year...                  metric: 0.425 metric_improv: 16.61 %\n",
      "nf: 3 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.477 metric_improv: 10.88 %\n",
      "nf: 4 cfeature: past_affind3...                metric: 0.510 metric_improv: 6.58 %\n",
      "nf: 5 cfeature: yearspan_flag...               metric: 0.512 metric_improv: 0.30 %\n",
      "nf: 6 cfeature: litgw_comm_im_dir_wei_pNone... metric: 0.538 metric_improv: 4.86 %\n",
      "nf: 7 cfeature: past_affind2...                metric: 0.557 metric_improv: 3.42 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 3007}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.375 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: delta_year...                  metric: 0.393 metric_improv: 4.60 %\n",
      "nf: 3 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.472 metric_improv: 16.64 %\n",
      "nf: 4 cfeature: cpop...                        metric: 0.514 metric_improv: 8.12 %\n",
      "nf: 5 cfeature: litgw_comm_im_dir_wei_pNone... metric: 0.536 metric_improv: 4.12 %\n",
      "nf: 6 cfeature: ksst2...                       metric: 0.543 metric_improv: 1.43 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 8922}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.361 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: lincs_comm_im_undir_unwei_p... metric: 0.424 metric_improv: 14.89 %\n",
      "nf: 3 cfeature: litgw_comm_im_dir_wei_pNone... metric: 0.445 metric_improv: 4.80 %\n",
      "nf: 4 cfeature: ai...                          metric: 0.486 metric_improv: 8.27 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 669}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.373 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: delta_year...                  metric: 0.418 metric_improv: 10.86 %\n",
      "nf: 3 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.493 metric_improv: 15.20 %\n",
      "nf: 4 cfeature: succfit_flag...                metric: 0.532 metric_improv: 7.35 %\n",
      "nf: 5 cfeature: past_affind...                 metric: 0.543 metric_improv: 1.94 %\n",
      "nf: 6 cfeature: past_affind1...                metric: 0.543 metric_improv: 0.00 %\n",
      "nf: 7 cfeature: litgw_comm_im_dir_unwei_p95... metric: 0.549 metric_improv: 1.14 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 2637}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.370 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: delta_year...                  metric: 0.433 metric_improv: 14.53 %\n",
      "nf: 3 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.483 metric_improv: 10.30 %\n",
      "nf: 4 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.523 metric_improv: 7.75 %\n",
      "nf: 5 cfeature: ai...                          metric: 0.535 metric_improv: 2.23 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 2304}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.356 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: delta_year...                  metric: 0.434 metric_improv: 17.94 %\n",
      "nf: 3 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.509 metric_improv: 14.85 %\n",
      "nf: 4 cfeature: past_affind2...                metric: 0.525 metric_improv: 2.91 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 4671}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.365 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: delta_year...                  metric: 0.411 metric_improv: 11.16 %\n",
      "nf: 3 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.498 metric_improv: 17.46 %\n",
      "nf: 4 cfeature: cpop...                        metric: 0.537 metric_improv: 7.25 %\n",
      "nf: 5 cfeature: lincs_comm_ml_undir_unwei_p... metric: 0.543 metric_improv: 1.10 %\n",
      "nf: 6 cfeature: ksst1...                       metric: 0.551 metric_improv: 1.55 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 1614}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.367 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.413 metric_improv: 11.26 %\n",
      "nf: 3 cfeature: delta_year...                  metric: 0.509 metric_improv: 18.80 %\n",
      "nf: 4 cfeature: cpop...                        metric: 0.541 metric_improv: 5.98 %\n",
      "nf: 5 cfeature: litgw_comm_im_dir_wei_pNone... metric: 0.563 metric_improv: 3.74 %\n",
      "nf: 6 cfeature: cpoprc2...                     metric: 0.576 metric_improv: 2.26 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 3253}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.376 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.419 metric_improv: 10.42 %\n",
      "nf: 3 cfeature: delta_year...                  metric: 0.481 metric_improv: 12.85 %\n",
      "nf: 4 cfeature: cden...                        metric: 0.511 metric_improv: 5.80 %\n",
      "nf: 5 cfeature: litgw_comm_im_dir_unwei_p95... metric: 0.532 metric_improv: 3.91 %\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 5377}\n",
      "nf: 1 cfeature: litgw_comm_im_undir_unwei_p... metric: 0.371 metric_improv: 100.00 %\n",
      "nf: 2 cfeature: delta_year...                  metric: 0.413 metric_improv: 10.19 %\n",
      "nf: 3 cfeature: litgw_comm_im_undir_wei_pNo... metric: 0.525 metric_improv: 21.34 %\n",
      "nf: 4 cfeature: lincs_comm_ml_undir_wei_pNo... metric: 0.532 metric_improv: 1.38 %\n",
      "Terminating early: no improvement.\n"
     ]
    }
   ],
   "source": [
    "func = partial(study_sample, dfw=dfw, dist=dist, feature_dict=feature_dict, metric_mode=mm,\n",
    "               model_type=model_type,\n",
    "               n_subtrials=n_subtrials, n_estimators=n_estimators,\n",
    "               log_reg_dict=log_reg_dict, verbose=verbose)\n",
    "\n",
    "print('Starting {0} processes...'.format(n_jobs))\n",
    "\n",
    "# lr seems to run 4x\n",
    "if n_jobs > 1:\n",
    "    with Pool(n_jobs) as p:\n",
    "        meta_report = p.map(func, seeds)\n",
    "else:\n",
    "    meta_report = list(map(func, seeds))\n",
    "\n",
    "# if datapath:\n",
    "#     fout = expanduser(join(datapath, '{0}_{1}_{2}_{3}_seed0_{4}.report.pgz'.format(origin, version,\n",
    "#                                                                                    an_version, model_type, seed0)))\n",
    "# else:\n",
    "#     fout = expanduser('~/data/kl/reports/{0}_{1}_{2}_{3}_seed0_{4}.report.pgz'.format(origin, version,\n",
    "#                                                                                       an_version,\n",
    "#                                                                                       model_type, seed0))\n",
    "\n",
    "# with gzip.open(fout, 'wb') as fp:\n",
    "#     pickle.dump(meta_report, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_par': 235,\n",
       " 'current_features': ['litgw_comm_im_undir_unwei_p95_eff_comm_size',\n",
       "  'delta_year',\n",
       "  'litgw_comm_im_undir_wei_pNone_eff_comm_size',\n",
       "  'past_affind3',\n",
       "  'yearspan_flag',\n",
       "  'litgw_comm_im_dir_wei_pNone_dyn_same_comm',\n",
       "  'past_affind2'],\n",
       " 'current_metrics': [0.3543356575761969,\n",
       "  0.4248993487140507,\n",
       "  0.4767629902036166,\n",
       "  0.5103540113326976,\n",
       "  0.511879927299675,\n",
       "  0.5380078880731337,\n",
       "  0.5570867439071006],\n",
       " 'current_vector_metrics': [{'corr': 0.19311290312487198,\n",
       "   'accuracy': {'normal': 0.7229842756774841, 'balanced': 0.3543356575761969},\n",
       "   'vector': {'precision': array([0.30291262, 0.96029056, 0.05378973]),\n",
       "    'recall': array([0.57777778, 0.74492863, 0.38596491]),\n",
       "    'f1': array([0.39745223, 0.83900994, 0.0944206 ])},\n",
       "   'macro': {'precision': 0.43899763643709816,\n",
       "    'recall': 0.5695571050507979,\n",
       "    'f1': 0.44362759101301735},\n",
       "   'exponent': {'precision': 0.5874150917795194,\n",
       "    'recall': 0.7481567239939292,\n",
       "    'f1': 0.61789744577049},\n",
       "   'main_metric': 0.3543356575761969,\n",
       "   'conf': array([[ 156,   61,   53],\n",
       "          [ 345, 1983,  334],\n",
       "          [  14,   21,   22]]),\n",
       "   'auroc': [0.8167558879217578, 0.7878782134790929, 0.6612575093942222]},\n",
       "  {'corr': 0.275406719803789,\n",
       "   'accuracy': {'normal': 0.7638006022080963, 'balanced': 0.4248993487140507},\n",
       "   'vector': {'precision': array([0.41518987, 0.96141479, 0.06235012]),\n",
       "    'recall': array([0.60740741, 0.78625094, 0.45614035]),\n",
       "    'f1': array([0.49323308, 0.86505476, 0.10970464])},\n",
       "   'macro': {'precision': 0.47965159477286096,\n",
       "    'recall': 0.6165995658093671,\n",
       "    'f1': 0.4893308291459473},\n",
       "   'exponent': {'precision': 0.6248566545097526,\n",
       "    'recall': 0.7804843395295911,\n",
       "    'f1': 0.6545352200614124},\n",
       "   'main_metric': 0.4248993487140507,\n",
       "   'conf': array([[ 164,   63,   43],\n",
       "          [ 221, 2093,  348],\n",
       "          [  10,   21,   26]]),\n",
       "   'auroc': [0.8545645866535899, 0.846054563375816, 0.749694837366267]},\n",
       "  {'corr': 0.2985511267249213,\n",
       "   'accuracy': {'normal': 0.819672131147541, 'balanced': 0.4767629902036166},\n",
       "   'vector': {'precision': array([0.51875   , 0.96865608, 0.08235294]),\n",
       "    'recall': array([0.61481481, 0.8474831 , 0.49122807]),\n",
       "    'f1': array([0.56271186, 0.90402725, 0.14105793])},\n",
       "   'macro': {'precision': 0.5232530055817948,\n",
       "    'recall': 0.6511753268024111,\n",
       "    'f1': 0.5359323493212943},\n",
       "   'exponent': {'precision': 0.6638061018574589,\n",
       "    'recall': 0.8018554576961151,\n",
       "    'f1': 0.6921738358548003},\n",
       "   'main_metric': 0.4767629902036166,\n",
       "   'conf': array([[ 166,   55,   49],\n",
       "          [ 143, 2256,  263],\n",
       "          [  11,   18,   28]]),\n",
       "   'auroc': [0.8718224292700203, 0.8913752737014549, 0.7765910342021493]},\n",
       "  {'corr': 0.336932030086231,\n",
       "   'accuracy': {'normal': 0.8069588491134159, 'balanced': 0.5103540113326976},\n",
       "   'vector': {'precision': array([0.47814208, 0.96711968, 0.09064327]),\n",
       "    'recall': array([0.64814815, 0.82870023, 0.54385965]),\n",
       "    'f1': array([0.55031447, 0.89257536, 0.15538847])},\n",
       "   'macro': {'precision': 0.5119683452351677,\n",
       "    'recall': 0.6735693408884651,\n",
       "    'f1': 0.5327594318934725},\n",
       "   'exponent': {'precision': 0.658656944128164,\n",
       "    'recall': 0.8176248752804945,\n",
       "    'f1': 0.693595779869289},\n",
       "   'main_metric': 0.5103540113326976,\n",
       "   'conf': array([[ 175,   56,   39],\n",
       "          [ 184, 2206,  272],\n",
       "          [   7,   19,   31]]),\n",
       "   'auroc': [0.8480466674839606, 0.8718560232700805, 0.7742723965438836]},\n",
       "  {'corr': 0.3281830216349317,\n",
       "   'accuracy': {'normal': 0.8032786885245902, 'balanced': 0.511879927299675},\n",
       "   'vector': {'precision': array([0.48179272, 0.96741524, 0.08864266]),\n",
       "    'recall': array([0.63703704, 0.82531931, 0.56140351]),\n",
       "    'f1': array([0.54864434, 0.89073586, 0.15311005])},\n",
       "   'macro': {'precision': 0.5126168706485511,\n",
       "    'recall': 0.6745866181997834,\n",
       "    'f1': 0.530830082165343},\n",
       "   'exponent': {'precision': 0.6584715866438402,\n",
       "    'recall': 0.8186285040064266,\n",
       "    'f1': 0.6919287087043777},\n",
       "   'main_metric': 0.511879927299675,\n",
       "   'conf': array([[ 172,   55,   43],\n",
       "          [ 179, 2197,  286],\n",
       "          [   6,   19,   32]]),\n",
       "   'auroc': [0.8480010352389904, 0.8665238709025198, 0.7752896053229936]},\n",
       "  {'corr': 0.3408901510466589,\n",
       "   'accuracy': {'normal': 0.8039478086316494, 'balanced': 0.5380078880731337},\n",
       "   'vector': {'precision': array([0.45382586, 0.96612407, 0.10385757]),\n",
       "    'recall': array([0.63703704, 0.82494365, 0.61403509]),\n",
       "    'f1': array([0.53004622, 0.8899696 , 0.17766497])},\n",
       "   'macro': {'precision': 0.5079358297991846,\n",
       "    'recall': 0.6920052587154225,\n",
       "    'f1': 0.5325602681479968},\n",
       "   'exponent': {'precision': 0.6596171624475929,\n",
       "    'recall': 0.8300046655350811,\n",
       "    'f1': 0.6976426571288478},\n",
       "   'main_metric': 0.5380078880731337,\n",
       "   'conf': array([[ 172,   60,   38],\n",
       "          [ 202, 2196,  264],\n",
       "          [   5,   17,   35]]),\n",
       "   'auroc': [0.8442081102801957, 0.8647409342496157, 0.8124626026184152]},\n",
       "  {'corr': 0.36014451604762454,\n",
       "   'accuracy': {'normal': 0.7989294078287053, 'balanced': 0.5570867439071006},\n",
       "   'vector': {'precision': array([0.44444444, 0.9674833 , 0.10619469]),\n",
       "    'recall': array([0.66666667, 0.81592787, 0.63157895]),\n",
       "    'f1': array([0.53333333, 0.88526595, 0.18181818])},\n",
       "   'macro': {'precision': 0.5060408103079131,\n",
       "    'recall': 0.7047244959380671,\n",
       "    'f1': 0.533472487252801},\n",
       "   'exponent': {'precision': 0.6587164074065824,\n",
       "    'recall': 0.8381677516670462,\n",
       "    'f1': 0.6991946335240554},\n",
       "   'main_metric': 0.5570867439071006,\n",
       "   'conf': array([[ 180,   57,   33],\n",
       "          [ 220, 2172,  270],\n",
       "          [   5,   16,   36]]),\n",
       "   'auroc': [0.8451956737907453, 0.8592255483793887, 0.8145568559871712]}],\n",
       " 'validation_metrics': {'corr': 0.32704465037320596,\n",
       "  'accuracy': {'normal': 0.8032786885245902, 'balanced': 0.5179480666261438},\n",
       "  'vector': {'precision': array([0.45273632, 0.96628217, 0.12312312]),\n",
       "   'recall': array([0.64768683, 0.82656546, 0.56164384]),\n",
       "   'f1': array([0.5329429 , 0.89097975, 0.20197044])},\n",
       "  'macro': {'precision': 0.5140472021903374,\n",
       "   'recall': 0.6786320444174292,\n",
       "   'f1': 0.5419643642616935},\n",
       "  'exponent': {'precision': 0.6689141345561561,\n",
       "   'recall': 0.8211251316925897,\n",
       "   'f1': 0.7077859459634515},\n",
       "  'main_metric': 0.5179480666261438,\n",
       "  'conf': array([[ 182,   55,   44],\n",
       "         [ 209, 2178,  248],\n",
       "         [  11,   21,   41]]),\n",
       "  'auroc': [0.8338211020989607, 0.8841309405117981, 0.8151154706202905]},\n",
       " 'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=17, n_jobs=1,\n",
       "             oob_score=False, random_state=4183, verbose=0,\n",
       "             warm_start=False),\n",
       " 'corr_all': litgw_comm_im_undir_unwei_p95_eff_comm_size   -0.150767\n",
       " delta_year                                    -0.167057\n",
       " litgw_comm_im_undir_wei_pNone_eff_comm_size   -0.114562\n",
       " past_affind3                                  -0.011145\n",
       " yearspan_flag                                 -0.019159\n",
       " litgw_comm_im_dir_wei_pNone_dyn_same_comm     -0.115679\n",
       " past_affind2                                  -0.018346\n",
       " guess                                          1.000000\n",
       " Name: guess, dtype: float64,\n",
       " 'corr_all_test': litgw_comm_im_undir_unwei_p95_eff_comm_size   -0.139347\n",
       " delta_year                                    -0.170783\n",
       " litgw_comm_im_undir_wei_pNone_eff_comm_size   -0.117549\n",
       " past_affind3                                  -0.023084\n",
       " yearspan_flag                                 -0.009223\n",
       " litgw_comm_im_dir_wei_pNone_dyn_same_comm     -0.137949\n",
       " past_affind2                                  -0.024935\n",
       " guess                                          1.000000\n",
       " Name: guess, dtype: float64,\n",
       " 'corr_all_valid': litgw_comm_im_undir_unwei_p95_eff_comm_size   -0.166767\n",
       " delta_year                                    -0.159647\n",
       " litgw_comm_im_undir_wei_pNone_eff_comm_size   -0.124685\n",
       " past_affind3                                  -0.013290\n",
       " yearspan_flag                                 -0.025856\n",
       " litgw_comm_im_dir_wei_pNone_dyn_same_comm     -0.101485\n",
       " past_affind2                                  -0.023571\n",
       " guess                                          1.000000\n",
       " Name: guess, dtype: float64}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_report[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_report[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
