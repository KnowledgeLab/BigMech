{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datahelpers.constants import iden, ye, ai, ps, up, dn, ar, ni, cexp, qcexp, nw, wi, dist, rdist, pm, \\\n",
    "                                    cpop, cden, ct, affs, aus\n",
    "from os.path import expanduser, join\n",
    "import pandas as pd\n",
    "from bm_support.add_features import generate_feature_groups\n",
    "from bm_support.supervised_aux import split_three_way\n",
    "from bm_support.supervised import select_features_dict\n",
    "from bm_support.add_features import normalize_columns\n",
    "from bm_support.supervised_aux import study_sample, metric_selector\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "from numpy.random import RandomState\n",
    "import gzip\n",
    "import pickle\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bm_support.supervised import simple_stratify\n",
    "from bm_support.supervised import select_features_dict, logit_pvalue, report_metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport bm_support.add_features\n",
    "%aimport bm_support.supervised_aux\n",
    "%aimport bm_support.supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_version = 12\n",
    "\n",
    "# origin = 'litgw'\n",
    "# version = 1\n",
    "\n",
    "# origin = 'lit'\n",
    "# version = 8\n",
    "\n",
    "origin = 'gw'\n",
    "version = 11\n",
    "\n",
    "# model_type = 'rf'\n",
    "# seed0 = 17\n",
    "n_trials = 1\n",
    "n_subtrials = 2\n",
    "n_estimators = 17\n",
    "# n_estimators = 55\n",
    "datapath = None\n",
    "# seed0 = 13\n",
    "seed0 = 1\n",
    "n_jobs = 1\n",
    "verbose = True\n",
    "model_type = 'lr'\n",
    "model_type = 'rf'\n",
    "\n",
    "\n",
    "min_log_alpha = -1\n",
    "max_log_alpha = 1\n",
    "log_reg_dict = {'min_log_alpha': min_log_alpha, 'max_log_alpha': max_log_alpha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cpop', 'cden', 'ksst', 'nhi', 'affiliations_affind', 'authors_affind', 'future_affind', 'past_affind', 'affiliations_suppind', 'authors_suppind', 'future_suppind', 'past_suppind', 'affiliations_comm_size', 'authors_comm_size', 'future_comm_size', 'past_comm_size', 'affiliations_ncomms', 'authors_ncomms', 'future_ncomms', 'past_ncomms', 'affiliations_ncomponents', 'authors_ncomponents', 'future_ncomponents', 'past_ncomponents', 'affiliations_size_ulist', 'authors_size_ulist', 'future_size_ulist', 'past_size_ulist', 'pre_authors', 'pre_affs']\n",
      "{'cpop': 8, 'cden': 8, 'ksst': 8, 'nhi': 2, 'affiliations_affind': 4, 'authors_affind': 4, 'future_affind': 4, 'past_affind': 4, 'affiliations_suppind': 4, 'authors_suppind': 4, 'future_suppind': 4, 'past_suppind': 4, 'affiliations_comm_size': 4, 'authors_comm_size': 4, 'future_comm_size': 4, 'past_comm_size': 4, 'affiliations_ncomms': 4, 'authors_ncomms': 4, 'future_ncomms': 4, 'past_ncomms': 4, 'affiliations_ncomponents': 4, 'authors_ncomponents': 4, 'future_ncomponents': 4, 'past_ncomponents': 4, 'affiliations_size_ulist': 4, 'authors_size_ulist': 4, 'future_size_ulist': 4, 'past_size_ulist': 4, 'pre_authors': 1, 'pre_affs': 1, 'citations': 12, 'time': 2, 'ai': 1, 'ar': 1, 'cite_count': 1, 'delta_year': 1, 'lincscomm_size': 5, 'lincssame_comm': 5, 'litgweff_comm_size': 12, 'litgwsame_comm': 12, 'litgwcsize_up': 6, 'litgwcsize_dn': 6}\n",
      "188 208\n",
      "['authors', 'cdf_exp', 'dn', 'guess', 'iid', 'len', 'max_year', 'mean', 'min_year', 'new_index', 'pmid', 'pop_density', 'pos', 'qcdf_exp', 'rdist', 'std', 'up', 'wid', 'wos_id', 'year']\n",
      "42\n",
      "Number of col families: 42. Keys: ['affiliations_affind', 'affiliations_comm_size', 'affiliations_ncomms', 'affiliations_ncomponents', 'affiliations_size_ulist', 'affiliations_suppind', 'ai', 'ar', 'authors_affind', 'authors_comm_size', 'authors_ncomms', 'authors_ncomponents', 'authors_size_ulist', 'authors_suppind', 'cden', 'citations', 'cite_count', 'cpop', 'delta_year', 'future_affind', 'future_comm_size', 'future_ncomms', 'future_ncomponents', 'future_size_ulist', 'future_suppind', 'ksst', 'lincscomm_size', 'lincssame_comm', 'litgwcsize_dn', 'litgwcsize_up', 'litgweff_comm_size', 'litgwsame_comm', 'nhi', 'past_affind', 'past_comm_size', 'past_ncomms', 'past_ncomponents', 'past_size_ulist', 'past_suppind', 'pre_affs', 'pre_authors', 'time']\n",
      "Number of col families (excl. future): 36. Keys: ['affiliations_affind', 'affiliations_comm_size', 'affiliations_ncomms', 'affiliations_ncomponents', 'affiliations_size_ulist', 'affiliations_suppind', 'ai', 'ar', 'authors_affind', 'authors_comm_size', 'authors_ncomms', 'authors_ncomponents', 'authors_size_ulist', 'authors_suppind', 'cden', 'citations', 'cite_count', 'cpop', 'delta_year', 'ksst', 'lincscomm_size', 'lincssame_comm', 'litgwcsize_dn', 'litgwcsize_up', 'litgweff_comm_size', 'litgwsame_comm', 'nhi', 'past_affind', 'past_comm_size', 'past_ncomms', 'past_ncomponents', 'past_size_ulist', 'past_suppind', 'pre_affs', 'pre_authors', 'time']\n",
      "15494 7878\n",
      "Experimental mask len 887\n",
      "Number of trial features: 90\n",
      "Number of notnull entries (over all features): 14943 from (15494,)\n"
     ]
    }
   ],
   "source": [
    "eps = 0.2\n",
    "upper_exp, lower_exp = 1 - eps, eps\n",
    "# thrs = [-1e-8, lower_exp, upper_exp, 1.0001e0]\n",
    "if datapath:\n",
    "    col_families = generate_feature_groups(expanduser(join(datapath, 'v12_columns.txt')))\n",
    "else:\n",
    "    col_families = generate_feature_groups(expanduser('~/data/kl/columns/v12_columns.txt'))\n",
    "\n",
    "if verbose:\n",
    "    print('Number of col families: {0}. Keys: {1}'.format(len(col_families), sorted(col_families.keys())))\n",
    "\n",
    "col_families = {k: v for k, v in col_families.items() if 'future' not in k}\n",
    "if verbose:\n",
    "    print('Number of col families (excl. future): {0}. Keys: {1}'.format(len(col_families),\n",
    "                                                                         sorted(col_families.keys())))\n",
    "\n",
    "columns_interest = [x for sublist in col_families.values() for x in sublist]\n",
    "if datapath:\n",
    "    df_path = expanduser(join(datapath, '{0}_{1}_{2}.h5'.format(origin, version, an_version)))\n",
    "else:\n",
    "    df_path = expanduser('~/data/kl/final/{0}_{1}_{2}.h5'.format(origin, version, an_version))\n",
    "\n",
    "df = pd.read_hdf(df_path, key='df')\n",
    "\n",
    "\n",
    "# mask: literome - mask out a specific interaction\n",
    "mask_lit = (df[up] == 7157) & (df[dn] == 1026)\n",
    "\n",
    "# mask:  interaction with more than 3 claims\n",
    "thr = 3\n",
    "mask_len_ = (df.groupby(ni).apply(lambda x: x.shape[0]) > thr)\n",
    "mask_max_len = df[ni].isin(mask_len_[mask_len_].index)\n",
    "print(mask_max_len.shape[0], sum(mask_max_len))\n",
    "\n",
    "# mask : interactions which are between\n",
    "eps_window_mean = 0.1\n",
    "mean_col = 0.5\n",
    "mask_exp = ((df[cexp] <= lower_exp - eps_window_mean) | (df[cexp] >= upper_exp + eps_window_mean)\n",
    "            # | ((df2[cexp] <= (mean_col + eps_window_mean)) & (df2[cexp] >= (mean_col - eps_window_mean)))\n",
    "            )\n",
    "\n",
    "feature_dict = deepcopy(col_families)\n",
    "# families = ['affiliations_affind', 'affiliations_comm_size', 'affiliations_ncomms',\n",
    "#             'affiliations_ncomponents', 'affiliations_size_ulist', 'affiliations_suppind',\n",
    "#             'ai', 'ar', 'authors_affind', 'authors_comm_size', 'authors_ncomms', 'authors_ncomponents',\n",
    "#             'authors_size_ulist', 'authors_suppind', 'cden', 'citations',\n",
    "#             'cite_count', 'cpop', 'delta_year', 'ksst', 'lincscomm_size', 'lincssame_comm',\n",
    "#             'litgwcsize_dn', 'litgwcsize_up',\n",
    "#             'litgweff_comm_size', 'litgwsame_comm', 'nhi', 'past_affind',\n",
    "#             'past_comm_size', 'past_ncomms', 'past_ncomponents',\n",
    "#             'past_size_ulist', 'past_suppind', 'pre_affs', 'pre_authors', 'time']\n",
    "families = ['affiliations_comm_size',\n",
    "            'ai', 'ar', 'cden', 'citations',\n",
    "            'cite_count', 'cpop', 'delta_year', 'ksst', 'lincscomm_size', 'lincssame_comm',\n",
    "            'litgweff_comm_size', 'litgwsame_comm', 'nhi', 'past_affind',\n",
    "            'past_comm_size', 'time']\n",
    "\n",
    "feature_dict = {k: v for k, v in feature_dict.items() if k in families}\n",
    "\n",
    "trial_features = [x for sublist in feature_dict.values() for x in sublist]\n",
    "\n",
    "feature_dict_inv = {}\n",
    "for k, v in feature_dict.items():\n",
    "    feature_dict_inv.update({x: k for x in v})\n",
    "\n",
    "# mask: not nulls in trial features\n",
    "masks = []\n",
    "for c in trial_features:\n",
    "    masks.append(df[c].notnull())\n",
    "\n",
    "mask_notnull = masks[0]\n",
    "for m in masks[1:]:\n",
    "    mask_notnull &= m\n",
    "\n",
    "print('Experimental mask len {0}'.format(sum(mask_exp)))\n",
    "print('Number of trial features: {0}'.format(len(trial_features)))\n",
    "print('Number of notnull entries (over all features): {0} from {1}'.format(sum(mask_notnull), mask_notnull.shape))\n",
    "\n",
    "if origin != 'gw':\n",
    "    mask_agg = mask_notnull & ~mask_lit\n",
    "else:\n",
    "    mask_agg = mask_notnull\n",
    "\n",
    "dfw = df.loc[mask_agg].copy()\n",
    "\n",
    "#metric to optimize for\n",
    "mm = 'accuracy'\n",
    "# mm = 'precision'\n",
    "\n",
    "target_column = 'litgw_comm_im_undir_wei_pNone_eff_comm_size'\n",
    "\n",
    "nmax = 5000\n",
    "\n",
    "rns = RandomState(seed0)\n",
    "seeds = rns.randint(nmax, size=n_trials)\n",
    "\n",
    "df_train, df_test, df_valid = split_three_way(dfw, seed0, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'lrg'\n",
    "model_type = 'rfr'\n",
    "\n",
    "if model_type == 'rf' or model_type == 'rfr':\n",
    "    param_dict = {'n_estimators': n_estimators, 'max_features': None, 'n_jobs': 1}\n",
    "else:\n",
    "    param_dict = {'n_jobs': 1}\n",
    "\n",
    "if model_type == 'rf' or model_type == 'rfr':\n",
    "    param_dict['random_state'] = 17\n",
    "elif model_type == 'lr':\n",
    "    param_dict['C'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_pool = [target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict_new = {k: list(v) for k, v in feature_dict.items() if not any([c in v for c in col_pool])}\n",
    "len(feature_dict), len(feature_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 235}\n",
      "nf: 1 cfeature: lincs_comm_im_undir_unwei_p... metric: -0.011 metric_improv: 100.00 %\n",
      "Fractional potential improvement: 0.06266838038560452\n",
      "nf: 2 cfeature: lincs_comm_ml_undir_wei_pNo... metric: -0.011 metric_improv: 6.27 %\n",
      "Fractional potential improvement: 0.015259073768838949\n",
      "nf: 3 cfeature: litgw_comm_ml_undir_unwei_p... metric: -0.010 metric_improv: 1.53 %\n",
      "Fractional potential improvement: 0.03373099514820699\n",
      "nf: 4 cfeature: litgw_comm_im_dir_wei_pNone... metric: -0.010 metric_improv: 3.37 %\n",
      "Fractional potential improvement: -0.0004962529924058545\n",
      "Terminating early: no improvement.\n",
      "model_dict {'n_estimators': 17, 'max_features': None, 'n_jobs': 1, 'random_state': 5192}\n",
      "nf: 1 cfeature: lincs_comm_im_undir_unwei_p... metric: -0.011 metric_improv: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "#metric to optimize for\n",
    "mm = 'accuracy'\n",
    "# mm = 'precision'\n",
    "\n",
    "target_column = 'litgw_comm_im_undir_wei_pNone_eff_comm_size'\n",
    "\n",
    "col_pool = [target_column]\n",
    "\n",
    "feature_dict_new = {k: list(v) for k, v in feature_dict.items() if not any([c in v for c in col_pool])}\n",
    "len(feature_dict), len(feature_dict_new)\n",
    "\n",
    "study_sample_flag = True\n",
    "# study_sample_flag = False\n",
    "model_type = 'lrg'\n",
    "model_type = 'rfr'\n",
    "verbose=True\n",
    "\n",
    "if study_sample_flag:\n",
    "    r = study_sample(dfw=dfw, target=target_column, feature_dict=feature_dict_new, metric_mode=mm,\n",
    "                       model_type=model_type,\n",
    "                       n_subtrials=n_subtrials, n_estimators=n_estimators,\n",
    "                       log_reg_dict=log_reg_dict, verbose=verbose, seed=seed0)\n",
    "else:\n",
    "    nmax = 5000\n",
    "    \n",
    "    rns = RandomState(seed0)\n",
    "    seeds = rns.randint(nmax, size=n_trials)\n",
    "    \n",
    "    df_train, df_test, df_valid = split_three_way(dfw, seed0, target_column)\n",
    "    \n",
    "    if model_type == 'rf' or model_type == 'rfr':\n",
    "        param_dict = {'n_estimators': n_estimators, 'max_features': None, 'n_jobs': 1}\n",
    "    else:\n",
    "        param_dict = {'n_jobs': 1}\n",
    "    \n",
    "    param_dict['random_state'] = 17\n",
    "    \n",
    "    if model_type == 'rf' or model_type == 'rfr':\n",
    "        param_dict = {'n_estimators': n_estimators, 'max_features': None, 'n_jobs': 1}\n",
    "    else:\n",
    "        param_dict = {'n_jobs': 1}\n",
    "    \n",
    "    if model_type == 'rf' or model_type == 'rfr':\n",
    "        param_dict['random_state'] = 17\n",
    "    elif model_type == 'lr':\n",
    "        param_dict['C'] = 1.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    r = select_features_dict(df_train, df_test, target_column, feature_dict_new, model_type='rfr', max_features_consider=8,\n",
    "                             metric_mode='accuracy', mode_scores=None,\n",
    "                             metric_uniform_exponent=0.5, eps_improvement=1e-6,\n",
    "                             model_dict=param_dict, verbose=True)\n",
    "    \n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['lincs_comm_im_undir_unwei_p95_eff_comm_size',\n",
       "  'lincs_comm_ml_undir_wei_pNone_eff_comm_size',\n",
       "  'litgw_comm_ml_undir_unwei_p95_same_comm',\n",
       "  'litgw_comm_im_dir_wei_pNone_same_comm',\n",
       "  'len_flag',\n",
       "  'ksst1'],\n",
       " [-0.011155945110876343,\n",
       "  -0.010562614208895147,\n",
       "  -0.010342602382690096,\n",
       "  -0.010060589922301551,\n",
       "  -0.010025177965262921,\n",
       "  -0.010016958874797003],\n",
       " [{'corr': 0.7903745331195964,\n",
       "   'mse': 0.011155945110876343,\n",
       "   'main_metric': -0.011155945110876343},\n",
       "  {'corr': 0.8374195704891597,\n",
       "   'mse': 0.010562614208895147,\n",
       "   'main_metric': -0.010562614208895147},\n",
       "  {'corr': 0.853030037726166,\n",
       "   'mse': 0.010342602382690096,\n",
       "   'main_metric': -0.010342602382690096},\n",
       "  {'corr': 0.8628943816236623,\n",
       "   'mse': 0.010060589922301551,\n",
       "   'main_metric': -0.010060589922301551},\n",
       "  {'corr': 0.8610588531763788,\n",
       "   'mse': 0.010025177965262921,\n",
       "   'main_metric': -0.010025177965262921},\n",
       "  {'corr': 0.8609635826302688,\n",
       "   'mse': 0.010016958874797003,\n",
       "   'main_metric': -0.010016958874797003}],\n",
       " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=17, n_jobs=1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
